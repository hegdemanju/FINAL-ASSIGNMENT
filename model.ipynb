{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acuurcy of this model is 0.8588796877420043 nearly 85 percent \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "df = pd.read_csv('data1.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the unwanted ones which are not reqquired to predict rainfall tom\n",
    "df = df.drop(columns=['Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','RISK_MM','Date', 'RISK_MM'],axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df, test_size = 0.2, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.drop(\"RainToday\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting cateogrical to numerical\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names=attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop(\"RainTomorrow\", axis = 1)\n",
    "y = train_set[\"RainTomorrow\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all these are inbuilt packages that i am using directly\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"])),\n",
    "        (\"imp\", SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"WindGustSpeed\", \"WindSpeed9am\", \"WindSpeed3pm\", \"Humidity9am\", \"Humidity3pm\",\n",
    "                                              \"Pressure9am\", \"Pressure3pm\", \"Temp9am\", \"Temp3pm\"])),\n",
    "        (\"imp\", SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ])\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical data into numerical data using dictonary method\n",
    "X_train_prepared = preprocess_pipeline.fit_transform(X)\n",
    "y_train_prepared = y.map({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_set.drop(\"RainTomorrow\", axis = 1)\n",
    "y_test = test_set[\"RainTomorrow\"].copy()\n",
    "\n",
    "X_test_prepared = preprocess_pipeline.fit_transform(X_test)\n",
    "y_test_prepared = y_test.map({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with adam optimizer\n",
      "Epoch 1/1\n",
      "113754/113754 [==============================] - 17s 145us/step - loss: 0.3620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1852377be48>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ann model that we learnt in lecture 5 using keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "n_cols =  X_train_prepared.shape[1]\n",
    "target =  to_categorical(y_train_prepared)\n",
    "\n",
    "def get_new_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape = (n_cols,)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "print(\"Testing model with adam optimizer\")\n",
    "model = get_new_model()\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n",
    "model.fit(X_train_prepared, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79627 samples, validate on 34127 samples\n",
      "Epoch 1/20\n",
      "79627/79627 [==============================] - 14s 170us/step - loss: 0.3676 - acc: 0.8411 - val_loss: 0.3505 - val_acc: 0.8465\n",
      "Epoch 2/20\n",
      "79627/79627 [==============================] - 12s 148us/step - loss: 0.3518 - acc: 0.8482 - val_loss: 0.3450 - val_acc: 0.8506\n",
      "Epoch 3/20\n",
      "79627/79627 [==============================] - 12s 150us/step - loss: 0.3446 - acc: 0.8510 - val_loss: 0.3422 - val_acc: 0.8513\n",
      "Epoch 4/20\n",
      "79627/79627 [==============================] - 12s 149us/step - loss: 0.3400 - acc: 0.8528 - val_loss: 0.3445 - val_acc: 0.8511\n",
      "Epoch 5/20\n",
      "79627/79627 [==============================] - 12s 150us/step - loss: 0.3356 - acc: 0.8550 - val_loss: 0.3440 - val_acc: 0.8507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1853b2936d8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2) \n",
    "\n",
    "# Without adding any nodes or layers\n",
    "model = get_new_model()\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_prepared, target, validation_split=0.3, epochs=20, callbacks = [early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79627 samples, validate on 34127 samples\n",
      "Epoch 1/20\n",
      "79627/79627 [==============================] - 15s 185us/step - loss: 0.3667 - acc: 0.8412 - val_loss: 0.3528 - val_acc: 0.8460\n",
      "Epoch 2/20\n",
      "79627/79627 [==============================] - 12s 156us/step - loss: 0.3517 - acc: 0.8483 - val_loss: 0.3445 - val_acc: 0.8503\n",
      "Epoch 3/20\n",
      "79627/79627 [==============================] - 12s 156us/step - loss: 0.3450 - acc: 0.8505 - val_loss: 0.3424 - val_acc: 0.8523\n",
      "Epoch 4/20\n",
      "79627/79627 [==============================] - 12s 157us/step - loss: 0.3394 - acc: 0.8529 - val_loss: 0.3478 - val_acc: 0.8512\n",
      "Epoch 5/20\n",
      "79627/79627 [==============================] - 12s 153us/step - loss: 0.3347 - acc: 0.8546 - val_loss: 0.3429 - val_acc: 0.8533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1853cad4f28>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are increasing the no of layers to decrease the loss \n",
    "model = Sequential()\n",
    "model.add(Dense(120, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_prepared, target, validation_split=0.3, epochs=20, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79627 samples, validate on 34127 samples\n",
      "Epoch 1/20\n",
      "79627/79627 [==============================] - 17s 210us/step - loss: 0.3672 - acc: 0.8410 - val_loss: 0.3485 - val_acc: 0.8489\n",
      "Epoch 2/20\n",
      "79627/79627 [==============================] - 14s 176us/step - loss: 0.3524 - acc: 0.8488 - val_loss: 0.3485 - val_acc: 0.8499\n",
      "Epoch 3/20\n",
      "79627/79627 [==============================] - 15s 192us/step - loss: 0.3455 - acc: 0.8505 - val_loss: 0.3433 - val_acc: 0.8514\n",
      "Epoch 4/20\n",
      "79627/79627 [==============================] - 15s 194us/step - loss: 0.3403 - acc: 0.8536 - val_loss: 0.3424 - val_acc: 0.8523\n",
      "Epoch 5/20\n",
      "79627/79627 [==============================] - 16s 196us/step - loss: 0.3351 - acc: 0.8557 - val_loss: 0.3440 - val_acc: 0.8534\n",
      "Epoch 6/20\n",
      "79627/79627 [==============================] - 15s 192us/step - loss: 0.3296 - acc: 0.8580 - val_loss: 0.3445 - val_acc: 0.8540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1853dfd4dd8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same as above\n",
    "model = Sequential()\n",
    "model.add(Dense(120, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_prepared, target, validation_split=0.3, epochs=20, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79627 samples, validate on 34127 samples\n",
      "Epoch 1/20\n",
      "79627/79627 [==============================] - 16s 207us/step - loss: 0.3667 - acc: 0.8407 - val_loss: 0.3557 - val_acc: 0.8470\n",
      "Epoch 2/20\n",
      "79627/79627 [==============================] - 14s 178us/step - loss: 0.3521 - acc: 0.8474 - val_loss: 0.3458 - val_acc: 0.8497\n",
      "Epoch 3/20\n",
      "79627/79627 [==============================] - 14s 178us/step - loss: 0.3451 - acc: 0.8516 - val_loss: 0.3445 - val_acc: 0.8526\n",
      "Epoch 4/20\n",
      "79627/79627 [==============================] - 14s 178us/step - loss: 0.3393 - acc: 0.8538 - val_loss: 0.3472 - val_acc: 0.8508\n",
      "Epoch 5/20\n",
      "79627/79627 [==============================] - 14s 175us/step - loss: 0.3349 - acc: 0.8551 - val_loss: 0.3412 - val_acc: 0.8531\n",
      "Epoch 6/20\n",
      "79627/79627 [==============================] - 14s 176us/step - loss: 0.3300 - acc: 0.8579 - val_loss: 0.3441 - val_acc: 0.8517\n",
      "Epoch 7/20\n",
      "79627/79627 [==============================] - 14s 177us/step - loss: 0.3259 - acc: 0.8600 - val_loss: 0.3480 - val_acc: 0.8512\n",
      "113754/113754 [==============================] - 7s 65us/step\n",
      "0.8588796877420043\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "model = Sequential()\n",
    "model.add(Dense(120, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_prepared, target, validation_split=0.3, epochs=20, callbacks = [early_stopping_monitor])\n",
    "#testing the data\n",
    "test_loss, test_acc = model.evaluate(X_train_prepared, target)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
